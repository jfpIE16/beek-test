{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import environment as env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexión exitosa!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn_string = \"dbname=%s user=%s host=%s password=%s port=%s\" % (env.DB_NAME, env.USERNAME, env.HOST, env.PASSWORD, env.PORT)\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    print(\"Conexión exitosa!\")\n",
    "except:\n",
    "    print(\"No se pudo realizar la conexión a la BD.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        year  week  wau\n",
      "0     2019.0  15.0   15\n",
      "1     2019.0  15.0    6\n",
      "2     2019.0  15.0   61\n",
      "3     2019.0  15.0   17\n",
      "4     2019.0  15.0    2\n",
      "...      ...   ...  ...\n",
      "5254  2018.0  49.0    6\n",
      "5255  2018.0  49.0    5\n",
      "5256  2018.0  49.0    4\n",
      "5257  2018.0  49.0   18\n",
      "5258  2018.0  49.0   79\n",
      "\n",
      "[5259 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the WAU - weekly unique active users (where an active = a user that plays an audiobook) for the dates provided in the data.\n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "        DATE_PART('isoyear', created_at) AS Year,\n",
    "        DATE_PART('week', created_at) AS Week,\n",
    "        COUNT(user_id) AS WAU\n",
    "    FROM \n",
    "        audiobook_plays\n",
    "    GROUP BY \n",
    "        DATE_PART('isoyear', created_at), \n",
    "        DATE_PART('week', created_at), \n",
    "        user_id\n",
    "    HAVING \n",
    "        COUNT(audiobook_id) > 1\n",
    "    ORDER BY \n",
    "        DATE_PART('isoyear', created_at) DESC, DATE_PART('week', created_at) DESC;\n",
    "\"\"\"\n",
    "wau = pd.read_sql(query, conn)\n",
    "print(wau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  avg_hours\n",
      "0   983885   16.27611\n",
      "1   991429   11.79961\n",
      "2   971029   11.39840\n",
      "3   966613    7.66967\n",
      "4   974151    7.64907\n",
      "5   986939    6.81231\n",
      "6   904922    6.12468\n",
      "7   951726    5.77219\n",
      "8   979560    5.69308\n",
      "9   971059    5.57944\n"
     ]
    }
   ],
   "source": [
    "# What is the average time listened (in hours) per user for the last 30 days for the data provided?\n",
    "query = \"\"\"\n",
    "    WITH max_date AS ( \n",
    "        SELECT \n",
    "            MAX(created_at) as max_date \n",
    "        FROM \n",
    "            audiobook_plays\n",
    "        LIMIT 1\n",
    "    )\n",
    "    SELECT\n",
    "        a.user_id,\n",
    "        ROUND(AVG(a.seconds) / 3600, 5) as avg_hours\n",
    "    FROM audiobook_plays a, max_date b\n",
    "    WHERE\n",
    "        a.created_at BETWEEN b.max_date - INTERVAL '30 DAY' AND b.max_date\n",
    "    GROUP BY\n",
    "        a.user_id\n",
    "    ORDER BY\n",
    "        ROUND(AVG(a.seconds) / 3600, 2) DESC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "avg_listen = pd.read_sql(query, conn)\n",
    "print(avg_listen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>previous_count</th>\n",
       "      <th>grow_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Young Adult Fiction / Fantasy / Wizards &amp; Witches</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  week                                           category  count  \\\n",
       "0  2019.0  15.0  Young Adult Fiction / Fantasy / Wizards & Witches     42   \n",
       "\n",
       "   previous_count  grow_percent  \n",
       "0               1          4200  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the book category that has been showing more popularity?\n",
    "# Why and how did you picked it?\n",
    "query = \"\"\"\n",
    "    WITH categories AS (\n",
    "        SELECT \n",
    "\t        id, \n",
    "\t        UNNEST(book_category_codes) AS category\n",
    "        FROM \n",
    "            audiobook\n",
    "    ),\n",
    "    category_names AS (\n",
    "        SELECT\n",
    "\t        A.*,\n",
    "\t        B.name\n",
    "        FROM\n",
    "\t        categories A\n",
    "        LEFT JOIN\n",
    "\t        book_categories B\n",
    "        ON\n",
    "\t        A.category = B.book_cateogory_code \n",
    "    ),\n",
    "    rankings AS (\n",
    "    SELECT\n",
    "        DATE_PART('isoyear', created_at) AS Year,\n",
    "        DATE_PART('week', created_at) AS Week,\n",
    "        B.name AS category,\n",
    "        COUNT(B.name) AS count\n",
    "    FROM \n",
    "        audiobook_plays A\n",
    "    LEFT JOIN \n",
    "    \tcategory_names B\n",
    "    ON\n",
    "    \tA.audiobook_id = B.id \n",
    "    WHERE\n",
    "    \tB.name is not null\n",
    "    GROUP BY \n",
    "        DATE_PART('isoyear', created_at), \n",
    "        DATE_PART('week', created_at),\n",
    "        B.name\n",
    "    ORDER BY \n",
    "        B.name desc,\n",
    "        DATE_PART('week', created_at) DESC,\n",
    "    \tDATE_PART('isoyear', created_at)\t\n",
    "    ),\n",
    "    previous_count AS (\n",
    "    SELECT \n",
    "    *,\n",
    "    LAG(count, 1)  OVER (ORDER BY category, week, year) AS previous_count\n",
    "    FROM rankings \n",
    "    ),\n",
    "    grow_index AS (\n",
    "    SELECT *, \n",
    "        CASE COALESCE(previous_count, 0)\n",
    "            WHEN 0 THEN 0\n",
    "            WHEN count THEN 0\n",
    "            ELSE (count * 100) / previous_count\n",
    "        END AS grow_percent\n",
    "     FROM previous_count\n",
    "    )\n",
    "    SELECT * FROM grow_index ORDER BY year desc, week desc, grow_percent desc LIMIT 1;\n",
    "\"\"\"\n",
    "popularity = pd.read_sql(query, conn)\n",
    "popularity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find two quality issues that affect the integrity of the database\n",
    "1. La tabla **book_categories** no está relacionada con la tabla **audiobook** esto puede provocar problemas de consistencia en los datos al momento de realizar actualizaciones / eliminaciones en las categorías.\n",
    "2. La tabla **audiobook_plays** que es la que tiene mas registros y representa una mayor transaccionalidad no tiene creados campos de partición, esto al momento de tener un aumento considerable de registros las operaciones serán cada vez mas pesadas dado que se aplican los *queries* en un solo fichero; mi recomendación personal es manejar particiones y utilizar estos campos para manejar consultas mas eficientes.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92e4be7b4f9f4275f97243b5d71a6e9ee9ebf49a4c03d6b53309b6bdb4d50e99"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('beek': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
